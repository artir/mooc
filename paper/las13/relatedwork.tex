\section{Related Work}
\label{sec:related work}
Student engagement is well known to be a significant factor in student learning success \cite{kuh}, but there is still limited work studying learner engagement in MOOCs. Our work is closest to \cite{kizilcec} where {\it Kizilcec et. al} attempt to understand learner disengagement in MOOCs. In their work (based on three online MOOC courses) the authors identify four prototypical trajectories of engagement and describe the set of features for comparing the different trajectories. Their work uses clustering to cluster user trajectories and identify them as engaged/disengaged based on which cluster they belong. Our work differs from \cite{kizilcec} in that we used a supervised method to learn a model of engagement from data. We use learner performance scores to train the model and use this model to predict learner performance in online courses. We model engagement more formally and show that it helps in predicting engagement.

Prior work \cite{kuh, carini} have studied the relationship between student engagement and academic performance for traditional classroom courses; they identify several metrics for user engagement (such as student-faculty interaction, level of academic challenge). \cite{carini} demonstrates quantitatively that though most engagement metrics are positively correlated to performance, the relationships in many cases can be weak. Our work borrows ideas from  \cite{kuh, carini}, but  online courses (our setting) are fundamentally different from traditional courses (number of students enrolled, student-faculty interactions, methods of assessment, lack of personal interaction); in this work we identify  metrics for learner engagement tailored for online courses and analyze how these engagement metrics relate to performance.